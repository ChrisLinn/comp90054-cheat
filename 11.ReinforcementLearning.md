# Reinforcement Learning

How to learn without a model

## Motivation
+ unknown environment
    * you don't have a model
+ Reinforcement Learning ~ Learning + Planning

## Approaches to AI Planning and Learning
+ ![ai-approaches](pics/ai-approaches.png)

### MCTS vs RL
+ Monte Carlo Tree Search samples a Policy Tree through experience. Recomputes Tree for evey new state.
+ Reinforcement Learning learns a full policy mapping states to actions through experience.

### Reinforcement Learning
+ don't know the environment
+ know the states
+ influence the env with actions, receive feedbacks(rewards)
+ Temporal Difference Learning, TD(Î»)
    * Use _experience_ to solve the _prediction_ problem
        - Combination of Monte Carlo (MC) ideas and Dynamic Programming (DP)
            + MC
                * learn from raw experience
                * without a model
            + DP
                * update estimates based on other learned estimates
                * no waiting for final outcome (bootstrap)

## Summary

### Offline vs Online
+ Offline
    * compute beforehand, may extract the policy for all states
+ Online
    * compute real-time and pick one/the best for the current state
+ know MDP (Stochastic)
    * Offline
        - Value Iteration
        - Policy Iteration
        - compute value&policy beforehand, won't change once done
    * Online
        - Classic Search
            + can be used in offline only when non-stochastic
        - Monte Carlo Search Tree
            + compute new tree each time, old tree useless
+ do not know MDP
    * Offline
        - Reinforcement Learning
            + train itself until being satisfying, then no more update
    * Online
        - Classic Search
            + can be used in offline only when non-stochastic
        - Monte Carlo Search Tree
            + compute new tree each time, old tree useless

### Reinforcement Learning
+ TD
    * look at someone's data
+ Sarsa
    * create data
    * current q
+ q-learning
    * create data
    * max q